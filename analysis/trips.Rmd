---
title: "Importing and inspecting the Divvy trip data"
author: "Peter Carbonetto"
output: html_document
---

<!-- Define defaults shared by all workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results="asis"}
```

<!-- Insert the code version (Git commit SHA1) if Git repository
 exists and R package git2r is installed -->
```{r code-version, echo=FALSE, results="asis"}
```
<br>

For this part of the lesson, I'm assuming you have worked through the
code in the [previous episode](stations.html), and your R session is
still open. If you have saved your R session using "save.image", you
can load it by running `load("workshop.RData")`.
<br>
<br>

## Installing the data.table package

Previously, we used "read.csv" to read in the data. However, if we try
to use it for the Divvy Trip data, we will see that it is very slow:

```{r, eval=FALSE}
trips <- read.csv(file = "../data/Divvy_Trips_2016.csv",
                  stringsAsFactors = FALSE,nrows = 1e5)
```

On your computer, it probably took a few seconds to read in the first
100,000 lines. This is tolerable, but consider that there is a total
of 3.6 million lines! Instead, we will use a function implemented in
the `data.table` package that is much faster.

Retrieve and install the package from CRAN:

```{r, eval=FALSE}
install.packages("data.table")
```

Load the package functions into your environment:

```{r, eval=TRUE}
library(data.table)
```

What functions were loaded? What can you do with this package? Use
this command to access the package documentation:

```{r, eval=FALSE}
help(package = data.table)
```

Package "vignettes" are also a great way to learn about a package,
e.g.,

```{r, eval=FALSE}
vignette("datatable-intro")
```
<br>

## Where are my packages?

In most cases, packages are either installed in R software directory,
or in your home directory. This will give you the list of package
installation locations:

```{r, eval=FALSE}
.libPaths()
```

When you install a new package, by default it is installed in the
first location.

To get the full list of packages, run

```{r, eval=FALSE}
installed.packages()
```

or

```{r, eval=FALSE}
rownames(installed.packages)
```

If you want to find out which packages are installed in each location,
run these commands:

```{r, eval=FALSE}
rownames(installed.packages(lib = .libPaths()[1]))
rownames(installed.packages(lib = .libPaths()[2]))
```
<br>

## Use data.table to load the Divvy trip data

Let's go ahead and load the data for the 3.6 million trips using the
"fread" funtion from the `data.table` package:

```{r, eval=FALSE}
trips <- fread("../data/Divvy_Trips_2016.csv",sep = ",",header = TRUE,
               stringsAsFactors = FALSE)
```

On my MacBook Air, this took about 30 seconds---not too bad. It will
take much longer if you use "read.csv". (Try it!)
<br>
<br>

## A first peek at the Divvy trip data

One annoying feature of "fread" is that it returns its own
"data.table" object format:

```{r, eval=FALSE}
class(trips)
```

I prefer working with a data frame since I am more used to it.

```{r, eval=FALSE}
class(trips) <- "data.frame"
```

We can use the same commands we used before to quickly get a quick
overview of the trip data:

```{r, eval=FALSE}
nrow(trips)
ncol(trips)
head(trips)
tail(trips)
summary(trips)
```

Unfortunately, the "summary" command isn't particularly useful in this
case. It will be more useful if we first convert some of the columns
to *factors*.
<br>
<br>

## Create some factor columns

A "factor" is also known as a "categorical variable". A couple good
candidates for categorical variables are the gender and usertype
columns:

```{r, eval=FALSE}
class(trips$gender)
class(trips$usertype)
summary(trips$gender)
summary(trips$usertype)
trips <- transform(trips,gender = factor(gender))
trips <- transform(trips,usertype = factor(usertype))
class(trips$gender)
class(trips$usertype)
summary(trips$gender)
summary(trips$usertype)
```

Here we observe an example of data coding Bad Practice---the missing
genders are simply empty character strings, which can be confusing. In
R, these "missing data" should always be assigned the special value NA
for "not assigned":

```{r, eval=FALSE}
i               <- which(trips$gender == "")
trips$gender[i] <- NA
trips           <- transform(trips,gender = factor(gender))
summary(trips$gender)
```

We will also see that it is very convert the "station name" columns to
factors. 

```{r, eval=FALSE}
trips <- transform(trips,
                   from_station_name = factor(from_station_name,
				                              rownames(stations)),
                   to_station_name   = factor(to_station_name,
				                              rownames(stations)))
```

For example, we can now quickly generate more informative summaries of
the trips by station:

```{r, eval=FALSE}
summary(trips$from_station_name)
```

What is the second argument of function "factor" for? Why did we set
the second argument of "factor" in this case, and not before?
<br>
<br>

## Convert the dates and times

In the previous section, we found that converting some table columns
to factors makes these columns easier to inspect (and eventually
analyze). Similarly, the dates and times aren't particularly useful
until we extract them from the character strings. Working with dates &
times in R is much more complicated so I won't explain in detail what
this code does, or how it works.

To convert the dates and times, I will use the `lubridate` package.

```{r, eval=FALSE}
install.packages("lubridate")
```

Here, I create my own function for parsing the dates and times to
accommodate the format of the dates and times provided in the Divvy
CSV files.

```{r, eval=TRUE}
parse.dt <- function (x) {
  out    <- suppressWarnings(mdy_hms(x))
  i      <- is.na(out)
  out[i] <- mdy_hm(x[i])
  return(out)
}
```

This code chunk parses the dates & times, then creates a new table
column, "start week":

```{r, eval=FALSE}
summary(trips$starttime)
trips <- transform(trips,starttime = parse.dt(starttime))
trips <- transform(trips,start.week = as.numeric(format(starttime,"%W")))
summary(trips$starttime)
summary(trips$startweek)
```
<br>

## Trips from University of Chicago

After having prepared the data more carefully, let's take a close look
at the trip data at the University of Chicago.

```{r, eval=FALSE}
stn.name <- "University Ave & 57th St"
uc.trips <- subset(trips,from_station_name == stn.name)
summary(uc.trips)
summary(uc.trips$start.day)
summary(uc.trips$to_station_name)
```

It is interesting to compare the day-of-the-week trends at University
of Chicago compared the rest of the city:

```{r, eval=FALSE}
rbind(summary(trips$start.day),
      summary(uc.trips$start.day))
```

It is also fun to look in more detail at the final destinations of all
people who started riding from the on-campus station:

```{r, eval=FALSE}
uc.dests <- summary(uc.trips$to_station_name)
i        <- which(uc.dests > 0)
uc.dests <- uc.dests[i]
uc.dests
data.frame(uc.dests)
```
<br>

## Save your session

Before moving to the next episode, let's save our current session to
be safe.

```{r, eval=FALSE}
save.image(file = "workshop.RData")
```
<br>

## Recap

Working with large data sets is often more difficult than working with
small data sets because it may require working with specialized
packages that can process the data efficiently.
