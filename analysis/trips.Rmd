---
title: "Import and inspect the Divvy trip data"
author: "Peter Carbonetto"
output: html_document
---

<!-- Define defaults shared by all workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results="asis"}
```

<!-- Insert the code version (Git commit SHA1) if Git repository
 exists and R package git2r is installed -->
```{r code-version, echo=FALSE, results="asis"}
```

For this part of the lesson, I'm assuming you have worked through the
code in the [previous episode](stations.html), and your R session is
still open. If you have saved your R session using the "save.image"
command, you can load the session data by running
`load("workshop.RData")`.

## Installing the data.table package

Previously, we used "read.csv" to read in the data. However, if we try
to use it for the Divvy Trip data, we will see that it is very slow:

```{r, eval=FALSE}
trips <- read.csv(file = "../data/Divvy_Trips_2016.csv",
                  stringsAsFactors = FALSE,nrows = 1e5)
```

On your computer, it probably took a few seconds to read in the first
100,000 lines. This is tolerable, but consider that there is a total
of 3.6 million lines in the CSV file! Instead, we will use a function
implemented in the
[data.table package](https://github.com/Rdatatable/data.table/wiki)
that is much faster.

Retrieve and install the package from CRAN:

```{r, eval=FALSE}
install.packages("data.table")
```

Load the package functions into your environment:

```{r, eval=TRUE}
library(data.table)
```

What functions were loaded? What can you do with this package? Use
this command to access the package documentation:

```{r, eval=FALSE}
help(package = data.table)
```

"Vignettes" are also a great way to learn about a package; e.g.,

```{r, eval=FALSE}
vignette("datatable-intro")
```

## Where are my packages?

In most cases, packages are either installed in the directory where
the R software is installed, or in your home directory. This will give
you the current list of package installation locations:

```{r, eval=FALSE}
.libPaths()
```

When you install a new package, by default it is installed in the
first location.

To get the full list of packages, run

```{r, eval=FALSE}
installed.packages()
```

or, for a more concise list,

```{r, eval=FALSE}
rownames(installed.packages)
```

If you want to find out which packages are installed in each location,
run these commands:

```{r, eval=FALSE}
rownames(installed.packages(lib = .libPaths()[1]))
rownames(installed.packages(lib = .libPaths()[2]))
```

## Use data.table to load the Divvy trip data

Let's go ahead and load the data for the 3.6 million trips using the
"fread" funtion from the `data.table` package:

```{r, eval=FALSE}
trips <- fread("../data/Divvy_Trips_2016.csv",sep = ",",header = TRUE,
               stringsAsFactors = FALSE)
```

On my MacBook Air, this took about 30 seconds---not too bad. It will
take much longer if you use "read.csv". (Try it!)

## A first peek at the Divvy trip data

One annoying feature of "fread" is that it returns its own
"data.table" object format:

```{r, eval=FALSE}
class(trips)
```

I prefer working with a data frame since I am more used to it.

```{r, eval=FALSE}
class(trips) <- "data.frame"
```

We can use the same commands we used before to quickly get an overview
of the trip data:

```{r, eval=FALSE}
nrow(trips)
ncol(trips)
head(trips)
tail(trips)
summary(trips)
```

Unfortunately, the "summary" command isn't particularly informative
for this data frame. It will be more useful if we first convert some
of the columns to *factors*.

## Create some factor columns

You may know a "factor" as a "categorical variable". In R, the
categories are called "levels". A couple good candidates for factors
are the gender and usertype columns:

```{r, eval=FALSE}
class(trips$gender)
class(trips$usertype)
summary(trips$gender)
summary(trips$usertype)
trips <- transform(trips,gender = factor(gender))
trips <- transform(trips,usertype = factor(usertype))
class(trips$gender)
class(trips$usertype)
summary(trips$gender)
summary(trips$usertype)
```

Unfortunately, we have stumbled upon an example of Bad Practice in
data encoding---the missing genders are simply empty character
strings. In R, "missing data" should always be assigned the special
value NA, short for "not assigned":

```{r, eval=FALSE}
i               <- which(trips$gender == "")
trips$gender[i] <- NA
trips           <- transform(trips,gender = factor(gender))
summary(trips$gender)
```

We will also see soon that it is useful to convert the "station name"
columns to factors.

```{r, eval=FALSE}
trips <- transform(trips,
                   from_station_name = factor(from_station_name,
				                              rownames(stations)),
                   to_station_name   = factor(to_station_name,
				                              rownames(stations)))
```

For example, we can now quickly generate more informative summaries of
the trips by station:

```{r, eval=FALSE}
summary(trips$from_station_name)
```

What is the second argument of function "factor" for? Why did we set
the second argument of "factor" in this case, and not before?

## Convert the dates and times

In the previous section, we explained that converting some table columns
to factors makes these columns easier to inspect (and eventually
analyze). Similarly, the dates and times aren't particularly useful
until we extract them from the character strings. Working with dates &
times in R is much more complicated so I won't explain in detail what
this code does exactly, or how it works.

To convert the dates and times, I will install and load the
`lubridate` package.

```{r, eval=FALSE}
install.packages("lubridate")
library(lubridate)
```

Here, I create my own function for parsing the dates and times to
accommodate the inconsistent format of the date & time data stored in
the Divvy CSV files.

```{r, eval=TRUE}
parse.dt <- function (x) {
  out    <- suppressWarnings(mdy_hms(x))
  i      <- is.na(out)
  out[i] <- mdy_hm(x[i])
  return(out)
}
```

This code chunk parses the dates & times, then creates a new table
column, "start week":

```{r, eval=FALSE}
summary(trips$starttime)
trips <- transform(trips,starttime = parse.dt(starttime))
trips <- transform(trips,start.week = as.numeric(format(starttime,"%W")))
trips <- transform(trips,
           start.day = factor(weekdays(as.Date(starttime)),
                              c("Monday","Tuesday","Wednesday","Thursday",
                                "Friday","Saturday","Sunday")))
summary(trips$starttime)
summary(trips$start.day)
summary(trips$start.week)
```

## Trips from University of Chicago

After having prepared the data more carefully, let's take a close look
at the trip data at the University of Chicago.

```{r, eval=FALSE}
uofcstn  <- "University Ave & 57th St"
uc.trips <- subset(trips,from_station_name == uofcstn)
summary(uc.trips)
summary(uc.trips$start.week)
summary(uc.trips$to_station_name)
```

It is interesting to compare the day-of-the-week trends at University
of Chicago compared the rest of the city:

```{r, eval=FALSE}
rbind(summary(trips$start.day),
      summary(uc.trips$start.day))
```

It is also fun to look in more detail at the final destinations of all
people who started riding from the on-campus station:

```{r, eval=FALSE}
uc.dests <- summary(uc.trips$to_station_name)
i        <- which(uc.dests > 0)
uc.dests <- uc.dests[i]
uc.dests
data.frame(uc.dests)
```

## Save your session

Before moving to the next episode, let's save our current session to
be safe.

```{r, eval=FALSE}
save.image(file = "workshop.RData")
```

## Recap

Working with large data sets is often more difficult than working with
small data sets because it can require the use of specialized packages
to process the data efficiently. However, once we take the effort to
process the data carefully, we can quickly learn about the data using
basic R commands such as "summary".

In the [next episode](plots.html), we will use the station and trip
data to generate some insightful plots.
